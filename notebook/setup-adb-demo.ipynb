{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup-demo\n",
    "\n",
    "デモセットアップ用のノートブックです。  \n",
    "ベクトルデータベース（Oracle Database 23ai）のセットアップやそれを活用した RAG を試験的に試すことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロガーの設定を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "log_level = os.getenv(\"LOG_LEVEL\", \"ERROR\").upper()\n",
    "handler.setLevel(log_level)\n",
    "logger.setLevel(log_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デモで使用する Word ファイルを `../data/*` に格納しておきます。  \n",
    "以下のコードでは、`../data/*` に格納された Word ファイルをすべて読み込み、テキストへ変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "\n",
    "files = glob.glob(\"../data/*.docx\")\n",
    "documents = []\n",
    "for file in files:\n",
    "    logger.debug(f\"loaded file name: {file}\")\n",
    "    loader = Docx2txtLoader(file)\n",
    "    document = loader.load()\n",
    "    logger.debug(f\"content: {document}\")\n",
    "    documents.extend(document)\n",
    "logger.info(f\"documents: {documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以降では、読み込んだテキストデータをチャンクと呼ばれる単位に分割し、それをベクトル化したのちに Oracle Database 23ai へ格納していきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "from langchain_community.vectorstores.oraclevs import OracleVS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.embeddings.oci_generative_ai import OCIGenAIEmbeddings\n",
    "from langchain_community.document_loaders.oracleai import OracleTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle Database との接続に必要となるパラメータを `../.env` から読み込みます。  \n",
    "以下のコードは、Autonomous Database が接続先の前提となっていますので、Base Database などに接続する場合は、以下のドキュメントを参考に、パラメータを一部修正してください。\n",
    "\n",
    "参考: \n",
    "\n",
    "- [python-oracledb - 4. Connecting to Oracle Database](https://python-oracledb.readthedocs.io/en/latest/user_guide/connection_handling.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Oracle Database 23ai\n",
    "username = os.getenv(\"USERNAME\")\n",
    "password = os.getenv(\"PASSWORD\")\n",
    "dsn = os.getenv(\"DSN\")\n",
    "config_dir = os.getenv(\"CONFIG_DIR\")\n",
    "wallet_dir = os.getenv(\"WALLET_DIR\")\n",
    "wallet_password = os.getenv(\"WALLET_PASSWORD\")\n",
    "table_name = os.getenv(\"TABLE_NAME\")\n",
    "\n",
    "logger.debug(f\"username: {username}\")\n",
    "logger.debug(f\"password: {password}\")\n",
    "logger.debug(f\"dsn: {dsn}\")\n",
    "logger.debug(f\"wallet dir: {wallet_dir}\")\n",
    "logger.debug(f\"wallet password: {wallet_password}\")\n",
    "logger.debug(f\"table name: {table_name}\")\n",
    "\n",
    "# for OCI Generative AI Service\n",
    "compartment_id = os.getenv(\"COMPARTMENT_ID\")\n",
    "service_endpoint = os.getenv(\"SERVICE_ENDPOINT\")\n",
    "\n",
    "logger.debug(f\"compartment id: {compartment_id}\")\n",
    "logger.debug(f\"service endpoint: {service_endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle Database とのコネクションを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = oracledb.connect(\n",
    "    dsn=dsn,\n",
    "    user=username,\n",
    "    password=password,\n",
    "    config_dir=config_dir,\n",
    "    wallet_location=wallet_dir,\n",
    "    wallet_password=wallet_password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データベースに格納する際のベクトルを得るための埋め込み関数とベクトルデータベースを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OCIGenAIEmbeddings(\n",
    "    auth_type=\"INSTANCE_PRINCIPAL\",\n",
    "    model_id=\"cohere.embed-multilingual-v3.0\",\n",
    "    service_endpoint=service_endpoint,\n",
    "    compartment_id=compartment_id,\n",
    ")\n",
    "\n",
    "oracle_vs = OracleVS(\n",
    "    client=connection,\n",
    "    embedding_function=embedding_function,\n",
    "    table_name=table_name,\n",
    "    distance_strategy=DistanceStrategy.COSINE,\n",
    "    query=\"What is Oracle Database?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cohere.embed-multilingual-v3.0 では、モデルの制約としてベクトル化対象の文章が最大 512 文字である必要があるため、読み込んだテキストをこれに収まるように分割（チャンキング）します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter_params = {\"split\": \"recursively\", \"max\": 300, \"by\": \"words\", \"overlap\": 30, \"normalize\": \"all\"}\n",
    "splitter = OracleTextSplitter(conn=connection, params=splitter_params)\n",
    "\n",
    "data = splitter.split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データベースにデータを追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_vs.add_documents(documents=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "簡易的な RAG のフローに沿って目的の回答が生成されることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI\n",
    "\n",
    "chat = ChatOCIGenAI(\n",
    "    auth_type=\"INSTANCE_PRINCIPAL\",\n",
    "    service_endpoint=service_endpoint,\n",
    "    compartment_id=compartment_id,\n",
    "    model_id=\"cohere.command-r-plus\",\n",
    "    is_stream=True,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 500,\n",
    "        \"top_p\": 0.75,\n",
    "        \"top_k\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    }\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "可能な限り、検索によって得られたコンテキストに則って回答を作成してください。\n",
    "コンテキスト: {context}\n",
    "---\n",
    "質問: {query}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": oracle_vs.as_retriever(), \"query\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | chat\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "res = chain.stream(\"海外出張って日当とかでるんでしたっけ？\")\n",
    "\n",
    "for chunk in res:\n",
    "    print(chunk, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
